{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":74608,"databundleVersionId":12966160,"sourceType":"competition"},{"sourceId":12189904,"sourceType":"datasetVersion","datasetId":7678100,"isSourceIdPinned":false},{"sourceId":12406655,"sourceType":"datasetVersion","datasetId":7824094}],"dockerImageVersionId":31089,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:        \n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-08-03T17:10:35.909975Z","iopub.execute_input":"2025-08-03T17:10:35.910297Z","iopub.status.idle":"2025-08-03T17:10:38.506615Z","shell.execute_reply.started":"2025-08-03T17:10:35.910264Z","shell.execute_reply":"2025-08-03T17:10:38.504775Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom xgboost import XGBRegressor\nfrom catboost import CatBoostRegressor, Pool\nfrom sklearn.model_selection import GridSearchCV\nfrom scipy.stats import randint\nimport lightgbm as lgb\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import make_scorer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import KFold, cross_val_score\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.model_selection import cross_val_predict\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.ensemble import ExtraTreesRegressor\nimport optuna\nfrom itertools import combinations\nfrom sklearn.model_selection import train_test_split\nimport xgboost as xgb\nimport lightgbm as lgb\nfrom catboost import CatBoostRegressor, Pool\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('ignore')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-03T17:10:44.428357Z","iopub.execute_input":"2025-08-03T17:10:44.428648Z","iopub.status.idle":"2025-08-03T17:10:44.432693Z","shell.execute_reply.started":"2025-08-03T17:10:44.428626Z","shell.execute_reply":"2025-08-03T17:10:44.431809Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"Raw_data=pd.read_csv('/kaggle/input/neurips-open-polymer-prediction-2025/train.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-03T17:10:47.999988Z","iopub.execute_input":"2025-08-03T17:10:48.000345Z","iopub.status.idle":"2025-08-03T17:10:48.037356Z","shell.execute_reply.started":"2025-08-03T17:10:48.000323Z","shell.execute_reply":"2025-08-03T17:10:48.036399Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import kagglehub\npath = kagglehub.dataset_download(\"senkin13/rdkit-2025-3-3-cp311\")\nprint(\"Path to dataset files\", path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-03T17:10:48.818395Z","iopub.execute_input":"2025-08-03T17:10:48.818726Z","iopub.status.idle":"2025-08-03T17:10:49.488603Z","shell.execute_reply.started":"2025-08-03T17:10:48.818693Z","shell.execute_reply":"2025-08-03T17:10:49.487373Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install /kaggle/input/rdkit-2025-3-3-cp311/rdkit-2025.3.3-cp311-cp311-manylinux_2_28_x86_64.whl","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-03T17:10:52.683274Z","iopub.execute_input":"2025-08-03T17:10:52.683585Z","iopub.status.idle":"2025-08-03T17:11:00.444587Z","shell.execute_reply.started":"2025-08-03T17:10:52.683562Z","shell.execute_reply":"2025-08-03T17:11:00.443501Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import networkx as nx\nfrom rdkit.Chem import AllChem\nfrom rdkit.Chem import Descriptors\nfrom rdkit.Chem import rdmolops\nfrom rdkit import Chem","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df1=pd.read_csv('/kaggle/input/neurips-dataset/tg.csv')\ndf2=pd.read_csv('/kaggle/input/neurips-dataset/ffv.csv')\ndf3=pd.read_csv('/kaggle/input/neurips-dataset/tc.csv')\ndf4=pd.read_csv('/kaggle/input/neurips-dataset/density.csv')\ndf5=pd.read_csv('/kaggle/input/neurips-dataset/rg.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-03T17:11:06.022313Z","iopub.execute_input":"2025-08-03T17:11:06.022576Z","iopub.status.idle":"2025-08-03T17:11:06.026842Z","shell.execute_reply.started":"2025-08-03T17:11:06.022552Z","shell.execute_reply":"2025-08-03T17:11:06.025955Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def GodMod(df, test,target):\n    pred1 = np.zeros(len(test))\n    \n    y = df.iloc[:, 0]\n    X = df.iloc[:, 1:]\n    X_train, X_val, y_train, y_val = train_test_split(\n        X, y, test_size=0.2, random_state=69)\n    xgb_params = {\n        \"objective\": \"reg:absoluteerror\",\n        \"eval_metric\": \"mae\",\n        \"n_estimators\": 2000,\n        \"learning_rate\": 0.02,\n        \"max_depth\": 6,\n        \"subsample\": 0.8,\n        \"colsample_bytree\": 0.8,\n        \"colsample_bylevel\": 0.8,\n        \"reg_alpha\": 0.1,\n        \"reg_lambda\": 0.1,\n        \"random_state\": 69,\n        \"n_jobs\": -1,\n        \"verbosity\": 0\n    }\n    if target == 1:\n        xgb_params.update({\n            \"n_estimators\": 3000,\n            \"learning_rate\": 0.01,\n            \"max_depth\": 8,\n            \"reg_alpha\": 0.05,\n            \"reg_lambda\": 0.05\n        })\n    model_xgb = xgb.XGBRegressor(**xgb_params)\n    model_xgb.fit(X_train, y_train,\n                  eval_set=[(X_val, y_val)],\n                  early_stopping_rounds=100,\n                  verbose=False)\n\n    pred1 = model_xgb.predict(test)\n   # pred1 /= 50\n    pred2 = np.zeros(len(test))\n   \n    y = df.iloc[:, 0]\n    X = df.iloc[:, 1:]\n    X_train, X_val, y_train, y_val = train_test_split(\n        X, y, test_size=0.2, random_state=69)\n    lgb_params = {\n        \"objective\": \"mae\",\n        \"metric\": \"mae\",\n        \"n_estimators\": 2000,\n        \"learning_rate\": 0.02,\n        \"num_leaves\": 63,\n        \"feature_fraction\": 0.8,\n        \"bagging_fraction\": 0.8,\n        \"bagging_freq\": 1,\n        \"min_child_samples\": 20,\n        \"random_state\": 69,\n        \"n_jobs\": -1,\n        \"verbosity\": -1\n    }\n    if target == 1:\n        lgb_params.update({\n            \"n_estimators\": 3000,\n            \"learning_rate\": 0.01,\n            \"num_leaves\": 127,\n            \"feature_fraction\": 0.7,\n            \"min_child_samples\": 10\n        })\n    model_lgb = lgb.LGBMRegressor(**lgb_params)\n    model_lgb.fit(X_train, y_train,\n                 eval_set=[(X_val, y_val)],\n                 callbacks=[lgb.early_stopping(100, verbose=False)])\n    pred2=model_lgb.predict(test)\n    #pred2/=50\n    pred3 = np.zeros(len(test))\n   \n    y = df.iloc[:, 0]\n    X = df.iloc[:, 1:]\n    X_train, X_val, y_train, y_val = train_test_split(\n        X, y, test_size=0.2, random_state=69)\n    catboost_params = {\n        \"iterations\": 3000,\n        \"learning_rate\": 0.05,\n        \"depth\": 7,\n        \"l2_leaf_reg\": 3,\n        \"random_seed\": 69,\n        \"loss_function\": \"MAE\",\n        \"task_type\": \"CPU\",\n        \"bootstrap_type\": \"Bernoulli\",\n        \"subsample\": 0.8,\n        \"verbose\": False,\n        \"od_type\": \"Iter\",\n        \"od_wait\": 100\n    }\n    \n        # Special settings for Density target\n    if target == 2:\n        catboost_params.update({\n            \"depth\": 9,\n            \"learning_rate\": 0.03,\n            \"l2_leaf_reg\": 5\n        })\n    \n    cat_train = Pool(\n        X_train, y_train,\n        cat_features=[col for col in X.columns if X[col].dtype == 'object']\n    )\n    cat_val = Pool(\n        X_val, y_val,\n        cat_features=[col for col in X.columns if X[col].dtype == 'object']\n    )\n    model_cat = CatBoostRegressor(**catboost_params)\n    model_cat.fit(cat_train,\n                 eval_set=cat_val,\n                 early_stopping_rounds=100,\n                 verbose=False)\n    pred3=model_cat.predict(test)\n    #pred3/=50\n    pred=(pred1+pred2+pred3)/3\n    \n    return pred","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-01T06:16:30.170961Z","iopub.execute_input":"2025-08-01T06:16:30.171871Z","iopub.status.idle":"2025-08-01T06:16:30.177763Z","shell.execute_reply.started":"2025-08-01T06:16:30.171841Z","shell.execute_reply":"2025-08-01T06:16:30.176717Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#extra tree\np1={'n_estimators': 2116, 'max_depth': 5, 'learning_rate': 0.08282502750192564, 'subsample': 0.6793910752113601, 'colsample_bytree': 0.7442014260176102, 'gamma': 4.755722698540227, 'reg_alpha': 0.06917547165803263, 'reg_lambda': 0.7353510890753056}\np2={'n_estimators': 1855, 'max_depth': 5, 'learning_rate': 0.06145325680863284, 'subsample': 0.8699297228633653, 'colsample_bytree': 0.9933170293118256, 'gamma': 0.00014825488273781091, 'reg_alpha': 0.0502587910984648, 'reg_lambda': 0.6493903850371053}\np3={'n_estimators': 700, 'max_depth': 7, 'learning_rate': 0.23893917169396547, 'subsample': 0.8046315493363868, 'colsample_bytree': 0.706559663958085, 'gamma': 0.0007392391224947704, 'reg_alpha': 0.07109604199415018, 'reg_lambda': 0.35302009921885363}\np4={'n_estimators': 910, 'max_depth': 5, 'learning_rate': 0.06401768100530354, 'subsample': 0.8143668727193376, 'colsample_bytree': 0.9240712642977564, 'gamma': 0.00010692540275645759, 'reg_alpha': 0.058782776860916625, 'reg_lambda': 0.02446757762273763}\np5={'n_estimators': 1411, 'max_depth': 13, 'learning_rate': 0.10131862608582638, 'subsample': 0.6424546915143092, 'colsample_bytree': 0.6809981271570222, 'gamma': 0.8257122531304489, 'reg_alpha': 0.675715562941502, 'reg_lambda': 0.9412687084570486}","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# import optuna\n# from sklearn.ensemble import ExtraTreesRegressor\n# from sklearn.model_selection import train_test_split\n# from sklearn.metrics import mean_absolute_error\n# import numpy as np\n\n# # Your 5 datasets\n# datasets = [df1, df2, df3, df4, df5]\n\n# # Store best models, test predictions, and best params\n# best_models = []\n# test_preds = []\n# best_params_list = []\n\n# # Define objective function\n# def objective(trial, X, y):\n#     model = ExtraTreesRegressor(\n#         n_estimators=trial.suggest_int('n_estimators', 100, 1000),\n#         max_depth=trial.suggest_int('max_depth', 3, 20),\n#         min_samples_split=trial.suggest_int('min_samples_split', 2, 10),\n#         min_samples_leaf=trial.suggest_int('min_samples_leaf', 1, 10),\n#         max_features=trial.suggest_float('max_features', 0.1, 1.0),\n#         bootstrap=trial.suggest_categorical('bootstrap', [True, False]),\n#         random_state=42,\n#         n_jobs=-1\n#     )\n#     X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n#     model.fit(X_train, y_train)\n#     preds = model.predict(X_val)\n#     return mean_absolute_error(y_val, preds)\n\n# # Loop over datasets\n# for idx, df in enumerate(datasets):\n#     print(f\"\\n🔍 Tuning for Target {idx+1}...\")\n\n#     y = df.iloc[:, 0]\n#     X = df.iloc[:, 1:]\n\n#     # Run Optuna\n#     study = optuna.create_study(direction='minimize')\n#     study.optimize(lambda trial: objective(trial, X, y), n_trials=50, timeout=300)\n\n#     # Get best parameters and model\n#     best_params = study.best_params\n#     best_params_list.append(best_params)\n    \n#     print(f\"✅ Best parameters for df{idx+1}:\\n{best_params}\\n\")\n\n#     model = ExtraTreesRegressor(**best_params, random_state=42, n_jobs=-1)\n#     model.fit(X, y)\n#     best_models.append(model)\n\n#     # Predict (you can customize testX as needed)\n#   #  test_pred = model.predict(testX)  # Replace testX with your actual test data\n# #    test_preds.append(test_pred)\n\n# # Final summary of best parameters\n# print(\"\\n🎯 All Best Parameters by Target:\\n\")\n# for i, params in enumerate(best_params_list, 1):\n#     print(f\"Target {i}: {params}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-01T06:14:20.680497Z","iopub.execute_input":"2025-08-01T06:14:20.680824Z","iopub.status.idle":"2025-08-01T06:14:20.698233Z","shell.execute_reply.started":"2025-08-01T06:14:20.680794Z","shell.execute_reply":"2025-08-01T06:14:20.697301Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**prediction/submission**","metadata":{}},{"cell_type":"code","source":"test=pd.read_csv('/kaggle/input/neurips-open-polymer-prediction-2025/test.csv', dtype=str)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-01T06:16:38.308284Z","iopub.execute_input":"2025-08-01T06:16:38.308712Z","iopub.status.idle":"2025-08-01T06:16:38.316109Z","shell.execute_reply.started":"2025-08-01T06:16:38.308682Z","shell.execute_reply":"2025-08-01T06:16:38.315215Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"prodata=test","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-01T06:16:38.685922Z","iopub.execute_input":"2025-08-01T06:16:38.686918Z","iopub.status.idle":"2025-08-01T06:16:38.690796Z","shell.execute_reply.started":"2025-08-01T06:16:38.686885Z","shell.execute_reply":"2025-08-01T06:16:38.689696Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"useless_cols = [   \n    \n    'MaxPartialCharge', \n    # Nan data\n    'BCUT2D_MWHI',\n    'BCUT2D_MWLOW',\n    'BCUT2D_CHGHI',\n    'BCUT2D_CHGLO',\n    'BCUT2D_LOGPHI',\n    'BCUT2D_LOGPLOW',\n    'BCUT2D_MRHI',\n    'BCUT2D_MRLOW',\n\n    # Constant data\n    'NumRadicalElectrons',\n    'SMR_VSA8',\n    'SlogP_VSA9',\n    'fr_barbitur',\n    'fr_benzodiazepine',\n    'fr_dihydropyridine',\n    'fr_epoxide',\n    'fr_isothiocyan',\n    'fr_lactam',\n    'fr_nitroso',\n    'fr_prisulfonamd',\n    'fr_thiocyan',\n\n    # High correlated data >0.95\n    'MaxEStateIndex',\n    'HeavyAtomMolWt',\n    'ExactMolWt',\n    'NumValenceElectrons',\n    'Chi0',\n    'Chi0n',\n    'Chi0v',\n    'Chi1',\n    'Chi1n',\n    'Chi1v',\n    'Chi2n',\n    'Kappa1',\n    'LabuteASA',\n    'HeavyAtomCount',\n    'MolMR',\n    'Chi3n',\n    'BertzCT',\n    'Chi2v',\n    'Chi4n',\n    'HallKierAlpha',\n    'Chi3v',\n    'Chi4v',\n    'MinAbsPartialCharge',\n    'MinPartialCharge',\n    'MaxAbsPartialCharge',\n    'FpDensityMorgan2',\n    'FpDensityMorgan3',\n    'Phi',\n    'Kappa3',\n    'fr_nitrile',\n    'SlogP_VSA6',\n    'NumAromaticCarbocycles',\n    'NumAromaticRings',\n    'fr_benzene',\n    'VSA_EState6',\n    'NOCount',\n    'fr_C_O',\n    'fr_C_O_noCOO',\n    'NumHDonors',\n    'fr_amide',\n    'fr_Nhpyrrole',\n    'fr_phenol',\n    'fr_phenol_noOrthoHbond',\n    'fr_COO2',\n    'fr_halogen',\n    'fr_diazo',\n    'fr_nitro_arom',\n    'fr_phos_ester'\n]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-01T06:16:40.697609Z","iopub.execute_input":"2025-08-01T06:16:40.697913Z","iopub.status.idle":"2025-08-01T06:16:40.704612Z","shell.execute_reply.started":"2025-08-01T06:16:40.697890Z","shell.execute_reply":"2025-08-01T06:16:40.703656Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def preprocessing(df):\n    desc_names = [desc[0] for desc in Descriptors.descList if desc[0] not in useless_cols]\n    descriptors = [compute_all_descriptors(smi) for smi in df['SMILES'].to_list()]\n\n    graph_feats = {'graph_diameter': [], 'avg_shortest_path': [], 'num_cycles': []}\n    for smile in df['SMILES']:\n         compute_graph_features(smile, graph_feats)\n        \n    result = pd.concat(\n        [\n            pd.DataFrame(descriptors, columns=desc_names),\n            pd.DataFrame(graph_feats)\n        ],\n        axis=1\n    )\n\n    result = result.replace([-np.inf, np.inf], np.nan)\n    return result","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-01T06:16:40.878671Z","iopub.execute_input":"2025-08-01T06:16:40.878948Z","iopub.status.idle":"2025-08-01T06:16:40.885222Z","shell.execute_reply.started":"2025-08-01T06:16:40.878928Z","shell.execute_reply":"2025-08-01T06:16:40.884389Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def compute_all_descriptors(smiles):\n    mol = Chem.MolFromSmiles(smiles)\n    if mol is None:\n        return [None] * len(desc_names)\n    return [desc[1](mol) for desc in Descriptors.descList if desc[0] not in useless_cols]\n\ndef compute_graph_features(smiles, graph_feats):\n    mol = Chem.MolFromSmiles(smiles)\n    adj = rdmolops.GetAdjacencyMatrix(mol)\n    G = nx.from_numpy_array(adj)\n\n    graph_feats['graph_diameter'].append(nx.diameter(G) if nx.is_connected(G) else 0)\n    graph_feats['avg_shortest_path'].append(nx.average_shortest_path_length(G) if nx.is_connected(G) else 0)\n    graph_feats['num_cycles'].append(len(list(nx.cycle_basis(G))))\n\ntest = pd.concat([test, preprocessing(test)], axis=1)\ntest['Ipc']=np.log10(test['Ipc'])\n\ntest=test.drop(['id','SMILES'],axis=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-01T06:16:43.818791Z","iopub.execute_input":"2025-08-01T06:16:43.819109Z","iopub.status.idle":"2025-08-01T06:16:43.896247Z","shell.execute_reply.started":"2025-08-01T06:16:43.819084Z","shell.execute_reply":"2025-08-01T06:16:43.895375Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-01T06:16:45.039649Z","iopub.execute_input":"2025-08-01T06:16:45.040253Z","iopub.status.idle":"2025-08-01T06:16:45.057881Z","shell.execute_reply.started":"2025-08-01T06:16:45.040221Z","shell.execute_reply":"2025-08-01T06:16:45.056724Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"prodata=test","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-01T06:16:47.116937Z","iopub.execute_input":"2025-08-01T06:16:47.117403Z","iopub.status.idle":"2025-08-01T06:16:47.121710Z","shell.execute_reply.started":"2025-08-01T06:16:47.117374Z","shell.execute_reply":"2025-08-01T06:16:47.120628Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pred1=GodMod(df1,prodata,1)\npred2=GodMod(df2,prodata,0)\npred3=GodMod(df3,prodata,0)\npred4=GodMod(df4,prodata,2)\npred5=GodMod(df5,prodata,0)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-01T06:16:47.507097Z","iopub.execute_input":"2025-08-01T06:16:47.507807Z","iopub.status.idle":"2025-08-01T06:38:13.157777Z","shell.execute_reply.started":"2025-08-01T06:16:47.507779Z","shell.execute_reply":"2025-08-01T06:38:13.156783Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for i in range (len(pred4)):\n    if(pred4[i]<0):\n        pred4[i]=pred4[i]*(-1)\n\nfor i in range (len(pred5)):\n    if(pred5[i]<0):\n        pred5[i]=pred5[i]*(-1)\n\n\nfor i in range (len(pred3)):\n    if(pred3[i]<0):\n        pred3[i]=pred3[i]*(-1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-01T06:38:13.491924Z","iopub.execute_input":"2025-08-01T06:38:13.492285Z","iopub.status.idle":"2025-08-01T06:38:13.498224Z","shell.execute_reply.started":"2025-08-01T06:38:13.492258Z","shell.execute_reply":"2025-08-01T06:38:13.497264Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"ss=pd.read_csv('/kaggle/input/neurips-open-polymer-prediction-2025/sample_submission.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-01T06:38:13.544958Z","iopub.execute_input":"2025-08-01T06:38:13.545333Z","iopub.status.idle":"2025-08-01T06:38:13.554449Z","shell.execute_reply.started":"2025-08-01T06:38:13.545307Z","shell.execute_reply":"2025-08-01T06:38:13.553524Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"ss['Tg']=pred1\nss['FFV']=pred2\nss['Tc']=pred3\nss['Density']=pred4\nss['Rg']=pred5","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-01T06:38:16.559923Z","iopub.execute_input":"2025-08-01T06:38:16.560264Z","iopub.status.idle":"2025-08-01T06:38:16.567536Z","shell.execute_reply.started":"2025-08-01T06:38:16.560230Z","shell.execute_reply":"2025-08-01T06:38:16.566502Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"submission=ss","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-01T06:38:17.492870Z","iopub.execute_input":"2025-08-01T06:38:17.493231Z","iopub.status.idle":"2025-08-01T06:38:17.497225Z","shell.execute_reply.started":"2025-08-01T06:38:17.493181Z","shell.execute_reply":"2025-08-01T06:38:17.496370Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-01T06:38:18.279134Z","iopub.execute_input":"2025-08-01T06:38:18.279499Z","iopub.status.idle":"2025-08-01T06:38:18.285460Z","shell.execute_reply.started":"2025-08-01T06:38:18.279476Z","shell.execute_reply":"2025-08-01T06:38:18.284448Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"ss.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-01T06:38:20.404887Z","iopub.execute_input":"2025-08-01T06:38:20.405809Z","iopub.status.idle":"2025-08-01T06:38:20.416500Z","shell.execute_reply.started":"2025-08-01T06:38:20.405775Z","shell.execute_reply":"2025-08-01T06:38:20.415565Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"submission.to_csv('submission.csv',index =False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-01T06:38:23.810092Z","iopub.execute_input":"2025-08-01T06:38:23.810447Z","iopub.status.idle":"2025-08-01T06:38:23.821432Z","shell.execute_reply.started":"2025-08-01T06:38:23.810421Z","shell.execute_reply":"2025-08-01T06:38:23.820403Z"}},"outputs":[],"execution_count":null}]}